{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SpaCy and TextaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-09T00:57:43.422407Z",
     "start_time": "2017-09-09T00:57:43.414952Z"
    }
   },
   "outputs": [],
   "source": [
    "doc_path = 'corpus_data/comp_ling.txt'\n",
    "\n",
    "with open(doc_path) as f:\n",
    "    input_doc = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-09T00:57:54.681865Z",
     "start_time": "2017-09-09T00:57:50.957943Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-09T00:57:57.984759Z",
     "start_time": "2017-09-09T00:57:57.973454Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textacy import text_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-09T02:08:00.225580Z",
     "start_time": "2017-09-09T02:08:00.211363Z"
    }
   },
   "outputs": [],
   "source": [
    "# input_doc = '''\n",
    "# Oxygen is a chemical element with symbol O and atomic number 8. A member of the chalcogen group on the periodic table, it is a highly reactive nonmetal and oxidizing agent that forms oxides with most elements as well as other compounds.\n",
    "# '''\n",
    "\n",
    "def to_spacy_doc(raw_doc):\n",
    "    '''Converts a raw string into a spaCy document'''\n",
    "    return nlp(raw_doc)\n",
    "\n",
    "def to_textacy_doc(raw_doc):\n",
    "    '''Converts a raw string into a spaCy doc, then a textacy doc'''\n",
    "    if isinstance(to_spacy_doc(\"test\"), spacy.tokens.doc.Doc):\n",
    "        return textacy.Doc(raw_doc)\n",
    "    else:\n",
    "        return textacy.Doc(nlp(raw_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-09T02:08:10.465640Z",
     "start_time": "2017-09-09T02:08:10.429246Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Today, \n",
       " \n",
       " The Association for Computational Linguistics, \n",
       " \n",
       " ..., 1, 2, 2.1, 2.2, 2.3, 2.3.1, 2.3.2, \n",
       " 2.4, 3, 4, 5, 6, 7\tReferences, 8\tExternal, United States, 1950s, Russian, 1960s, one, one, one, four, one, Crucially, Pólya, modern-day, English, One, One, English, IBM, over 4.5 million words, American, English, One, two, early in the lifetime of a field of study, English, Japanese, Japanese, Japanese, October 2015, only half, Alan Turing, Turing Test, 1950, Alan Turing, one day, two, one, Turing, Today, Turing, Joseph Weizenbaum, MIT, ELIZA, One, ELIZA, Joseph Weizenbaum, MIT, 1966, Rogerian, ELIZA, ELIZA, ELIZA, first, first, Markov, translation.[25] The, German, French, first, five, ELIZA, Siri, Bayesian, Bledsoe, Browing, 1959, one, Bayesian, Mosteller, Wallace, 1963, Federalist Papers, Madison, 1971, Terry Winograd, SHRDLU, SHRDLU, NASA, LUNAR, Apollo, 1960s and 1970s, Markov, Rabiner, 1989.[32, late 70s, IBM, Bayesian, Apple, Siri, Google Translate, Social, Twitter, four, four]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_named_entities(doc):\n",
    "    nes = textacy.extract.named_entities(doc)\n",
    "    return [ne for ne in nes]\n",
    "\n",
    "get_named_entities(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-09T02:14:10.699235Z",
     "start_time": "2017-09-09T02:14:10.696096Z"
    }
   },
   "outputs": [],
   "source": [
    "if not isinstance(doc, textacy.doc.Doc):\n",
    "        print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'automated_readability_index': 22.352141689526015,\n",
       " 'coleman_liau_index': 16.682927688311693,\n",
       " 'flesch_kincaid_grade_level': 19.052077766395673,\n",
       " 'flesch_readability_ease': 19.26507900874003,\n",
       " 'gulpease_index': 41.068861371186955,\n",
       " 'gunning_fog_index': 22.472696136278014,\n",
       " 'lix': 72.24939361765064,\n",
       " 'smog_index': 18.80095838887095,\n",
       " 'wiener_sachtextformel': 12.265282847241465}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_readability_stats(textacy_doc):\n",
    "    ts = text_stats.TextStats(textacy_doc)\n",
    "    return ts.readability_stats\n",
    "\n",
    "get_readability_stats(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('language', 0.02416255077377969),\n",
       " ('linguistic', 0.02043304879128454),\n",
       " ('computational', 0.01746222784332213),\n",
       " ('human', 0.011689631474031183),\n",
       " ('computer', 0.011480717062340147),\n",
       " ('model', 0.011188761077018177),\n",
       " ('word', 0.011081683346972649),\n",
       " ('approach', 0.008327125663422037),\n",
       " ('speech', 0.007841891597153119),\n",
       " ('program', 0.007792902818308204)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textacy.keyterms.key_terms_from_semantic_network(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-09T02:20:01.789808Z",
     "start_time": "2017-09-09T02:20:01.766571Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['language',\n",
       " 'linguistic',\n",
       " 'computational',\n",
       " 'human',\n",
       " 'computer',\n",
       " 'model',\n",
       " 'word',\n",
       " 'approach',\n",
       " 'speech',\n",
       " 'program']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_textacy_key_terms(doc):\n",
    "    if not isinstance(doc, textacy.doc.Doc):\n",
    "        doc = to_textacy_doc(doc)\n",
    "    term_prob_pairs = textacy.keyterms.key_terms_from_semantic_network(doc)\n",
    "    terms = [term[0] for term in term_prob_pairs]\n",
    "    return terms\n",
    "get_textacy_key_terms(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'textacy' has no attribute 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-d9a2aee523e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# textacy.corpus.Corpus.load(corpus_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtextacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCapitolWords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mTaggedText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkovify\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mText\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'textacy' has no attribute 'datasets'"
     ]
    }
   ],
   "source": [
    "import markovify\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "\n",
    "corpus_path = \"/corpus_data/comp_ling.txt\"\n",
    "corpus_name = \"comp_ling\"\n",
    "# corpus = textacy.Corpus.load(corpus_path, \n",
    "#         name=corpus_name, compression='gzip')\n",
    "\n",
    "#corpus = textacy.Corpus(\"en\", texts=[as_textacy_doc(input_doc)])\n",
    "# textacy.corpus.Corpus.load(corpus_path)\n",
    "\n",
    "corpus = textacy.datasets.CapitolWords()\n",
    "\n",
    "class TaggedText(markovify.Text):\n",
    "\n",
    "    def sentence_split(self, text):\n",
    "        \"\"\"\n",
    "        Splits full-text string into a list of sentences.\n",
    "        \"\"\"\n",
    "        sentence_list = []\n",
    "        for doc in corpus:\n",
    "            sentence_list += list(doc.sents)\n",
    "\n",
    "        return sentence_list\n",
    "\n",
    "    def word_split(self, sentence):\n",
    "        \"\"\"\n",
    "        Splits a sentence into a list of words.\n",
    "        \"\"\"\n",
    "        return [\"::\".join((word.orth_,word.pos_)) for word in sentence]\n",
    "\n",
    "    def word_join(self, words):\n",
    "        sentence = \" \".join(word.split(\"::\")[0] for word in words)\n",
    "        return sentence\n",
    "\n",
    "    def test_sentence_input(self, sentence):\n",
    "        \"\"\"\n",
    "        A basic sentence filter. This one rejects sentences that contain\n",
    "        the type of punctuation that would look strange on its own\n",
    "        in a randomly-generated sentence. \n",
    "        \"\"\"\n",
    "        sentence = sentence.text\n",
    "        reject_pat = re.compile(r\"(^')|('$)|\\s'|'\\s|[\\\"(\\(\\)\\[\\])]\")\n",
    "        # Decode unicode, mainly to normalize fancy quotation marks\n",
    "        if sentence.__class__.__name__ == \"str\":\n",
    "            decoded = sentence\n",
    "        else:\n",
    "            decoded = unidecode(sentence)\n",
    "        # Sentence shouldn't contain problematic characters\n",
    "        if re.search(reject_pat, decoded): return False\n",
    "        return True\n",
    "\n",
    "    def generate_corpus(self, text):\n",
    "        \"\"\"\n",
    "        Given a text string, returns a list of lists; that is, a list of\n",
    "        \"sentences,\" each of which is a list of words. Before splitting into \n",
    "        words, the sentences are filtered through `self.test_sentence_input`\n",
    "        \"\"\"\n",
    "        sentences = self.sentence_split(text)\n",
    "        passing = filter(self.test_sentence_input, sentences)\n",
    "        runs = map(self.word_split, sentences)\n",
    "        print(runs[0])\n",
    "        return runs\n",
    "\n",
    "# Generated the model\n",
    "model = TaggedText(input_doc)\n",
    "# A sentence based on the model\n",
    "print(model.make_sentence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>log_probability</th>\n",
       "      <th>stop?</th>\n",
       "      <th>punctuation?</th>\n",
       "      <th>whitespace?</th>\n",
       "      <th>number?</th>\n",
       "      <th>out of vocab.?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Computational</td>\n",
       "      <td>-19.579313</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linguistics</td>\n",
       "      <td>-19.579313</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is</td>\n",
       "      <td>-4.329765</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>an</td>\n",
       "      <td>-5.953294</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>interdisciplinary</td>\n",
       "      <td>-19.579313</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>field</td>\n",
       "      <td>-9.710699</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>concerned</td>\n",
       "      <td>-9.861534</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>with</td>\n",
       "      <td>-5.363765</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the</td>\n",
       "      <td>-3.425446</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>statistical</td>\n",
       "      <td>-11.639928</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>or</td>\n",
       "      <td>-5.715355</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rule</td>\n",
       "      <td>-9.545105</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-</td>\n",
       "      <td>-5.202416</td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>based</td>\n",
       "      <td>-8.318480</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>modeling</td>\n",
       "      <td>-19.579313</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>of</td>\n",
       "      <td>-4.128464</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>natural</td>\n",
       "      <td>-9.312656</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>language</td>\n",
       "      <td>-8.811478</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>from</td>\n",
       "      <td>-6.028811</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>a</td>\n",
       "      <td>-3.983075</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>computational</td>\n",
       "      <td>-19.579313</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>perspective</td>\n",
       "      <td>-9.924529</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>,</td>\n",
       "      <td>-3.391480</td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>as</td>\n",
       "      <td>-5.507394</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>well</td>\n",
       "      <td>-7.117937</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>as</td>\n",
       "      <td>-5.507394</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>the</td>\n",
       "      <td>-3.425446</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>study</td>\n",
       "      <td>-9.603720</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>of</td>\n",
       "      <td>-4.128464</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>appropriate</td>\n",
       "      <td>-10.032200</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>pictures</td>\n",
       "      <td>-9.748672</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3727</th>\n",
       "      <td>of</td>\n",
       "      <td>-4.128464</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>a</td>\n",
       "      <td>-3.983075</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3729</th>\n",
       "      <td>red</td>\n",
       "      <td>-9.453293</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3730</th>\n",
       "      <td>truck</td>\n",
       "      <td>-10.898046</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3731</th>\n",
       "      <td>,</td>\n",
       "      <td>-3.391480</td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3732</th>\n",
       "      <td>the</td>\n",
       "      <td>-3.425446</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3733</th>\n",
       "      <td>search</td>\n",
       "      <td>-9.428295</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3734</th>\n",
       "      <td>engine</td>\n",
       "      <td>-10.291152</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3735</th>\n",
       "      <td>will</td>\n",
       "      <td>-6.105684</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3736</th>\n",
       "      <td>still</td>\n",
       "      <td>-7.043760</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3737</th>\n",
       "      <td>find</td>\n",
       "      <td>-7.562676</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3738</th>\n",
       "      <td>the</td>\n",
       "      <td>-3.425446</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3739</th>\n",
       "      <td>information</td>\n",
       "      <td>-8.817930</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3740</th>\n",
       "      <td>desired</td>\n",
       "      <td>-11.827469</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3741</th>\n",
       "      <td>by</td>\n",
       "      <td>-6.114920</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3742</th>\n",
       "      <td>matching</td>\n",
       "      <td>-11.781653</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3743</th>\n",
       "      <td>words</td>\n",
       "      <td>-8.599854</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3744</th>\n",
       "      <td>such</td>\n",
       "      <td>-7.619059</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3745</th>\n",
       "      <td>as</td>\n",
       "      <td>-5.507394</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3746</th>\n",
       "      <td>\"</td>\n",
       "      <td>-4.700859</td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3747</th>\n",
       "      <td>four</td>\n",
       "      <td>-9.416868</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3748</th>\n",
       "      <td>-</td>\n",
       "      <td>-5.202416</td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749</th>\n",
       "      <td>wheeled</td>\n",
       "      <td>-19.579313</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3750</th>\n",
       "      <td>\"</td>\n",
       "      <td>-4.700859</td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3751</th>\n",
       "      <td>with</td>\n",
       "      <td>-5.363765</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3752</th>\n",
       "      <td>\"</td>\n",
       "      <td>-4.700859</td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3753</th>\n",
       "      <td>car\".[37</td>\n",
       "      <td>-19.579313</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3754</th>\n",
       "      <td>]</td>\n",
       "      <td>-5.498423</td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3755</th>\n",
       "      <td>\\n\\n</td>\n",
       "      <td>-4.458347</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3756 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   text  log_probability stop? punctuation? whitespace?  \\\n",
       "0         Computational       -19.579313                                  \n",
       "1           linguistics       -19.579313                                  \n",
       "2                    is        -4.329765   Yes                            \n",
       "3                    an        -5.953294   Yes                            \n",
       "4     interdisciplinary       -19.579313                                  \n",
       "5                 field        -9.710699                                  \n",
       "6             concerned        -9.861534                                  \n",
       "7                  with        -5.363765   Yes                            \n",
       "8                   the        -3.425446   Yes                            \n",
       "9           statistical       -11.639928                                  \n",
       "10                   or        -5.715355   Yes                            \n",
       "11                 rule        -9.545105                                  \n",
       "12                    -        -5.202416                Yes               \n",
       "13                based        -8.318480                                  \n",
       "14             modeling       -19.579313                                  \n",
       "15                   of        -4.128464   Yes                            \n",
       "16              natural        -9.312656                                  \n",
       "17             language        -8.811478                                  \n",
       "18                 from        -6.028811   Yes                            \n",
       "19                    a        -3.983075   Yes                            \n",
       "20        computational       -19.579313                                  \n",
       "21          perspective        -9.924529                                  \n",
       "22                    ,        -3.391480                Yes               \n",
       "23                   as        -5.507394   Yes                            \n",
       "24                 well        -7.117937   Yes                            \n",
       "25                   as        -5.507394   Yes                            \n",
       "26                  the        -3.425446   Yes                            \n",
       "27                study        -9.603720                                  \n",
       "28                   of        -4.128464   Yes                            \n",
       "29          appropriate       -10.032200                                  \n",
       "...                 ...              ...   ...          ...         ...   \n",
       "3726           pictures        -9.748672                                  \n",
       "3727                 of        -4.128464   Yes                            \n",
       "3728                  a        -3.983075   Yes                            \n",
       "3729                red        -9.453293                                  \n",
       "3730              truck       -10.898046                                  \n",
       "3731                  ,        -3.391480                Yes               \n",
       "3732                the        -3.425446   Yes                            \n",
       "3733             search        -9.428295                                  \n",
       "3734             engine       -10.291152                                  \n",
       "3735               will        -6.105684   Yes                            \n",
       "3736              still        -7.043760   Yes                            \n",
       "3737               find        -7.562676                                  \n",
       "3738                the        -3.425446   Yes                            \n",
       "3739        information        -8.817930                                  \n",
       "3740            desired       -11.827469                                  \n",
       "3741                 by        -6.114920   Yes                            \n",
       "3742           matching       -11.781653                                  \n",
       "3743              words        -8.599854                                  \n",
       "3744               such        -7.619059   Yes                            \n",
       "3745                 as        -5.507394   Yes                            \n",
       "3746                  \"        -4.700859                Yes               \n",
       "3747               four        -9.416868   Yes                            \n",
       "3748                  -        -5.202416                Yes               \n",
       "3749            wheeled       -19.579313                                  \n",
       "3750                  \"        -4.700859                Yes               \n",
       "3751               with        -5.363765   Yes                            \n",
       "3752                  \"        -4.700859                Yes               \n",
       "3753           car\".[37       -19.579313                                  \n",
       "3754                  ]        -5.498423                Yes               \n",
       "3755               \\n\\n        -4.458347                            Yes   \n",
       "\n",
       "     number? out of vocab.?  \n",
       "0                            \n",
       "1                            \n",
       "2                            \n",
       "3                            \n",
       "4                            \n",
       "5                            \n",
       "6                            \n",
       "7                            \n",
       "8                            \n",
       "9                            \n",
       "10                           \n",
       "11                           \n",
       "12                           \n",
       "13                           \n",
       "14                           \n",
       "15                           \n",
       "16                           \n",
       "17                           \n",
       "18                           \n",
       "19                           \n",
       "20                           \n",
       "21                           \n",
       "22                           \n",
       "23                           \n",
       "24                           \n",
       "25                           \n",
       "26                           \n",
       "27                           \n",
       "28                           \n",
       "29                           \n",
       "...      ...            ...  \n",
       "3726                         \n",
       "3727                         \n",
       "3728                         \n",
       "3729                         \n",
       "3730                         \n",
       "3731                         \n",
       "3732                         \n",
       "3733                         \n",
       "3734                         \n",
       "3735                         \n",
       "3736                         \n",
       "3737                         \n",
       "3738                         \n",
       "3739                         \n",
       "3740                         \n",
       "3741                         \n",
       "3742                         \n",
       "3743                         \n",
       "3744                         \n",
       "3745                         \n",
       "3746                         \n",
       "3747     Yes                 \n",
       "3748                         \n",
       "3749                         \n",
       "3750                         \n",
       "3751                         \n",
       "3752                         \n",
       "3753                    Yes  \n",
       "3754                         \n",
       "3755                         \n",
       "\n",
       "[3756 rows x 7 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "token_attributes = [(token.orth_,\n",
    "                     token.prob,\n",
    "                     token.is_stop,\n",
    "                     token.is_punct,\n",
    "                     token.is_space,\n",
    "                     token.like_num,\n",
    "                     token.is_oov)\n",
    "                    for token in doc]\n",
    "\n",
    "df = pd.DataFrame(token_attributes,\n",
    "                  columns=['text',\n",
    "                           'log_probability',\n",
    "                           'stop?',\n",
    "                           'punctuation?',\n",
    "                           'whitespace?',\n",
    "                           'number?',\n",
    "                           'out of vocab.?'])\n",
    "\n",
    "df.loc[:, 'stop?':'out of vocab.?'] = (df.loc[:, 'stop?':'out of vocab.?']\n",
    "                                       .applymap(lambda x: u'Yes' if x else u''))\n",
    "                                               \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_related_terms(token, topn=10):\n",
    "    \"\"\"\n",
    "    look up the topn most similar terms to token\n",
    "    and print them as a formatted list\n",
    "    \"\"\"\n",
    "\n",
    "    for word, similarity in food2vec.most_similar(positive=[token], topn=topn):\n",
    "\n",
    "        print u'{:20} {}'.format(word, round(similarity, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-09T07:45:39.498843Z",
     "start_time": "2017-09-09T07:45:39.490281Z"
    }
   },
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "from wikipedia import DisambiguationError, PageError, RedirectError\n",
    "\n",
    "def get_wiki_page(search_string, summary=True, content=True):\n",
    "    '''Returns results from searching for search_string with wikipedia wrapper library. \n",
    "       Note: Makes a web request'''\n",
    "    try:\n",
    "        page = wikipedia.page(search_string)\n",
    "        page_data = {\"url\":page.url}\n",
    "        if content:\n",
    "            page_data[\"content\"] = page.content # Full text content of page.\n",
    "        if summary:\n",
    "            page_data[\"summary\"] = page.summary # Summary section only.\n",
    "    \n",
    "    except DisambiguationError as e:\n",
    "        return get_wiki_page(e.options[0]) #naively choose first option\n",
    "    except Exception as e:\n",
    "        return None\n",
    "    \n",
    "    return page_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-09T07:50:46.320592Z",
     "start_time": "2017-09-09T07:50:44.697097Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davideverling/anaconda/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Users/davideverling/anaconda/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://en.wikipedia.org/wiki/Lon_(name)'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_wiki_page(\"Lon\")['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-09T07:32:00.320682Z",
     "start_time": "2017-09-09T07:32:00.314803Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_named_entities(text):\n",
    "    doc = nlp(text)\n",
    "    named_entities_list = []\n",
    "    for ent in doc.ents:\n",
    "        wiki_url = get_wiki_url(str(ent))\n",
    "        if wiki_url:\n",
    "            named_entities_list.append((ent.label_, ent.text, wiki_url))\n",
    "        else:\n",
    "            named_entities_list.append((ent.label_, ent.text))\n",
    "    \n",
    "    return named_entities_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-09T05:23:31.457864Z",
     "start_time": "2017-09-09T05:23:31.445282Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<a href=\"www.google.com\" class=link_class title=\"Custom Title\">Google</a>'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bleach\n",
    "\n",
    "def set_link_title(attrs, new=False):\n",
    "    attrs[(None, u'title')] = u'AI-provided Link'\n",
    "    return attrs\n",
    "\n",
    "def linkify(string):\n",
    "    '''Calls bleach.linkify.\n",
    "    Converts urls in the input string into links. \n",
    "    Returns a string of HTML.'''\n",
    "    if type(string) != str:\n",
    "        raise TypeError(\"input should be a string\")\n",
    "        \n",
    "    linker = Linker(callbacks=[set_link_title])\n",
    "    return bleach.linkify(string)\n",
    "\n",
    "def create_hyperlink(url, display_text, attrs=\"\"):\n",
    "    '''Optional attrs is a string of tag attributes.\n",
    "       Example call:\n",
    "       create_hyperlink('www.google.com', 'Google', \n",
    "       ... attrs = 'class=link_class title=\"Custom Title\"')'''\n",
    "    hyperlink_format = '<a href=\"{link}\" {attrs}>{text}</a>'\n",
    "    return hyperlink_format.format(link=url, attrs=attrs, text=display_text)\n",
    "\n",
    "create_hyperlink('www.google.com', 'Google', attrs='class=link_class title=\"Custom Title\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-09T05:26:07.922785Z",
     "start_time": "2017-09-09T05:26:07.227018Z"
    }
   },
   "outputs": [],
   "source": [
    "nes = get_named_entities(\"London is a cool city. It is where Winston Churchill once lived. Also Guy McMiggles.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-09T05:37:53.062100Z",
     "start_time": "2017-09-09T05:37:53.054221Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<a href=\"https://en.wikipedia.org/wiki/London\" class=\"GPE\" title=\"GPE\">London</a>',\n",
       " '<a href=\"https://en.wikipedia.org/wiki/Winston_Churchill\" class=\"PERSON\" title=\"PERSON\">Winston Churchill</a>',\n",
       " '<a href=\"https://en.wikipedia.org/wiki/Shane_Filan\" class=\"PERSON\" title=\"PERSON\">Guy McMiggles</a>']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def linkify_entity(named_entity_tuple):\n",
    "    '''Operates on tuples from get_named_entities(). Returns HTML string.'''\n",
    "    ent_type, label, url = named_entity_tuple #unpacks tuple\n",
    "    attrs = 'class=\"{ent_type}\" title=\"{ent_type}\"'.format(ent_type=ent_type)\n",
    "    return create_hyperlink(url, label, attrs=attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Empath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-09T02:46:37.335489Z",
     "start_time": "2017-09-09T02:46:37.313277Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from empath import Empath\n",
    "lexicon = Empath()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-09T02:47:22.614804Z",
     "start_time": "2017-09-09T02:47:22.597389Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'achievement': 0.0012221203788573174,\n",
       " 'affection': 0.0006110601894286587,\n",
       " 'aggression': 0.00030553009471432935,\n",
       " 'air_travel': 0.0,\n",
       " 'alcohol': 0.0,\n",
       " 'ancient': 0.00030553009471432935,\n",
       " 'anger': 0.0006110601894286587,\n",
       " 'animal': 0.003360831041857623,\n",
       " 'anonymity': 0.0006110601894286587,\n",
       " 'anticipation': 0.0,\n",
       " 'appearance': 0.002749770852428964,\n",
       " 'art': 0.002444240757714635,\n",
       " 'attractive': 0.0,\n",
       " 'banking': 0.0,\n",
       " 'beach': 0.0,\n",
       " 'beauty': 0.00030553009471432935,\n",
       " 'blue_collar_job': 0.0,\n",
       " 'body': 0.0,\n",
       " 'breaking': 0.00030553009471432935,\n",
       " 'business': 0.010388023220287198,\n",
       " 'car': 0.0006110601894286587,\n",
       " 'celebration': 0.0015276504735716467,\n",
       " 'cheerfulness': 0.0,\n",
       " 'childish': 0.00030553009471432935,\n",
       " 'children': 0.002444240757714635,\n",
       " 'cleaning': 0.00030553009471432935,\n",
       " 'clothing': 0.00030553009471432935,\n",
       " 'cold': 0.00030553009471432935,\n",
       " 'college': 0.0058050717995722576,\n",
       " 'communication': 0.011610143599144515,\n",
       " 'competing': 0.0006110601894286587,\n",
       " 'computer': 0.00977696303085854,\n",
       " 'confusion': 0.0009165902841429881,\n",
       " 'contentment': 0.0,\n",
       " 'cooking': 0.0,\n",
       " 'crime': 0.0,\n",
       " 'dance': 0.00030553009471432935,\n",
       " 'death': 0.00030553009471432935,\n",
       " 'deception': 0.00030553009471432935,\n",
       " 'disappointment': 0.0009165902841429881,\n",
       " 'disgust': 0.0,\n",
       " 'dispute': 0.0009165902841429881,\n",
       " 'divine': 0.00030553009471432935,\n",
       " 'domestic_work': 0.00030553009471432935,\n",
       " 'dominant_heirarchical': 0.00030553009471432935,\n",
       " 'dominant_personality': 0.0,\n",
       " 'driving': 0.0006110601894286587,\n",
       " 'eating': 0.0,\n",
       " 'economics': 0.0030553009471432934,\n",
       " 'emotional': 0.0006110601894286587,\n",
       " 'envy': 0.0006110601894286587,\n",
       " 'exasperation': 0.0,\n",
       " 'exercise': 0.00030553009471432935,\n",
       " 'exotic': 0.00030553009471432935,\n",
       " 'fabric': 0.0009165902841429881,\n",
       " 'family': 0.0012221203788573174,\n",
       " 'farming': 0.0,\n",
       " 'fashion': 0.0030553009471432934,\n",
       " 'fear': 0.0,\n",
       " 'feminine': 0.0012221203788573174,\n",
       " 'fight': 0.00030553009471432935,\n",
       " 'fire': 0.00030553009471432935,\n",
       " 'friends': 0.00030553009471432935,\n",
       " 'fun': 0.0,\n",
       " 'furniture': 0.00030553009471432935,\n",
       " 'gain': 0.0018331805682859762,\n",
       " 'giving': 0.0030553009471432934,\n",
       " 'government': 0.0030553009471432934,\n",
       " 'hate': 0.0006110601894286587,\n",
       " 'healing': 0.0036663611365719525,\n",
       " 'health': 0.0006110601894286587,\n",
       " 'hearing': 0.0012221203788573174,\n",
       " 'help': 0.0015276504735716467,\n",
       " 'heroic': 0.0012221203788573174,\n",
       " 'hiking': 0.002444240757714635,\n",
       " 'hipster': 0.0009165902841429881,\n",
       " 'home': 0.00030553009471432935,\n",
       " 'horror': 0.0,\n",
       " 'hygiene': 0.0,\n",
       " 'independence': 0.0009165902841429881,\n",
       " 'injury': 0.0006110601894286587,\n",
       " 'internet': 0.016804155209288116,\n",
       " 'irritability': 0.0,\n",
       " 'journalism': 0.003360831041857623,\n",
       " 'joy': 0.0,\n",
       " 'kill': 0.0,\n",
       " 'law': 0.0006110601894286587,\n",
       " 'leader': 0.002444240757714635,\n",
       " 'legend': 0.0009165902841429881,\n",
       " 'leisure': 0.0009165902841429881,\n",
       " 'liquid': 0.0,\n",
       " 'listen': 0.0006110601894286587,\n",
       " 'love': 0.0,\n",
       " 'lust': 0.0,\n",
       " 'magic': 0.0,\n",
       " 'masculine': 0.00030553009471432935,\n",
       " 'medical_emergency': 0.0006110601894286587,\n",
       " 'medieval': 0.00030553009471432935,\n",
       " 'meeting': 0.0058050717995722576,\n",
       " 'messaging': 0.010388023220287198,\n",
       " 'military': 0.0006110601894286587,\n",
       " 'money': 0.00030553009471432935,\n",
       " 'monster': 0.0,\n",
       " 'morning': 0.0012221203788573174,\n",
       " 'movement': 0.0006110601894286587,\n",
       " 'music': 0.0009165902841429881,\n",
       " 'musical': 0.0018331805682859762,\n",
       " 'negative_emotion': 0.0009165902841429881,\n",
       " 'neglect': 0.0,\n",
       " 'negotiate': 0.0,\n",
       " 'nervousness': 0.0,\n",
       " 'night': 0.0,\n",
       " 'noise': 0.00030553009471432935,\n",
       " 'occupation': 0.0006110601894286587,\n",
       " 'ocean': 0.00030553009471432935,\n",
       " 'office': 0.010999083409715857,\n",
       " 'optimism': 0.003360831041857623,\n",
       " 'order': 0.002444240757714635,\n",
       " 'pain': 0.0,\n",
       " 'party': 0.0012221203788573174,\n",
       " 'payment': 0.00030553009471432935,\n",
       " 'pet': 0.0,\n",
       " 'philosophy': 0.0030553009471432934,\n",
       " 'phone': 0.00458295142071494,\n",
       " 'plant': 0.002749770852428964,\n",
       " 'play': 0.0009165902841429881,\n",
       " 'politeness': 0.005499541704857928,\n",
       " 'politics': 0.0006110601894286587,\n",
       " 'poor': 0.0,\n",
       " 'positive_emotion': 0.006721662083715246,\n",
       " 'power': 0.0012221203788573174,\n",
       " 'pride': 0.0009165902841429881,\n",
       " 'prison': 0.0,\n",
       " 'programming': 0.019859456156431407,\n",
       " 'rage': 0.0,\n",
       " 'reading': 0.005194011610143599,\n",
       " 'real_estate': 0.0,\n",
       " 'religion': 0.0012221203788573174,\n",
       " 'restaurant': 0.0018331805682859762,\n",
       " 'ridicule': 0.0,\n",
       " 'royalty': 0.0006110601894286587,\n",
       " 'rural': 0.0006110601894286587,\n",
       " 'sadness': 0.0,\n",
       " 'sailing': 0.0,\n",
       " 'school': 0.012832263978001834,\n",
       " 'science': 0.021081576535288724,\n",
       " 'sexual': 0.00030553009471432935,\n",
       " 'shame': 0.00030553009471432935,\n",
       " 'shape_and_size': 0.00458295142071494,\n",
       " 'ship': 0.0,\n",
       " 'shopping': 0.0009165902841429881,\n",
       " 'sleep': 0.0006110601894286587,\n",
       " 'smell': 0.0,\n",
       " 'social_media': 0.007332722273143905,\n",
       " 'sound': 0.00030553009471432935,\n",
       " 'speaking': 0.021387106630003056,\n",
       " 'sports': 0.002749770852428964,\n",
       " 'stealing': 0.0006110601894286587,\n",
       " 'strength': 0.0036663611365719525,\n",
       " 'suffering': 0.00030553009471432935,\n",
       " 'superhero': 0.0,\n",
       " 'surprise': 0.0009165902841429881,\n",
       " 'swearing_terms': 0.0,\n",
       " 'swimming': 0.0,\n",
       " 'sympathy': 0.00488848151542927,\n",
       " 'technology': 0.016498625114573784,\n",
       " 'terrorism': 0.0,\n",
       " 'timidity': 0.00030553009471432935,\n",
       " 'tool': 0.0058050717995722576,\n",
       " 'torment': 0.0,\n",
       " 'tourism': 0.0,\n",
       " 'toy': 0.0009165902841429881,\n",
       " 'traveling': 0.0006110601894286587,\n",
       " 'trust': 0.007638252367858234,\n",
       " 'ugliness': 0.0,\n",
       " 'urban': 0.00030553009471432935,\n",
       " 'vacation': 0.00030553009471432935,\n",
       " 'valuable': 0.0006110601894286587,\n",
       " 'vehicle': 0.0006110601894286587,\n",
       " 'violence': 0.0,\n",
       " 'war': 0.00030553009471432935,\n",
       " 'warmth': 0.0,\n",
       " 'water': 0.0,\n",
       " 'weakness': 0.00030553009471432935,\n",
       " 'wealthy': 0.0009165902841429881,\n",
       " 'weapon': 0.0012221203788573174,\n",
       " 'weather': 0.00030553009471432935,\n",
       " 'wedding': 0.0,\n",
       " 'white_collar_job': 0.0009165902841429881,\n",
       " 'work': 0.011610143599144515,\n",
       " 'worship': 0.0006110601894286587,\n",
       " 'writing': 0.0018331805682859762,\n",
       " 'youth': 0.00030553009471432935,\n",
       " 'zest': 0.0}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon.analyze(input_doc, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-09T07:00:51.257865Z",
     "start_time": "2017-09-09T07:00:51.254868Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import chromelogger as console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-09T07:03:31.501416Z",
     "start_time": "2017-09-09T07:03:31.492563Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def index():\n",
    "    \n",
    "    console.log('Hello console!')\n",
    "    console.get_header()\n",
    "    return \n",
    "\n",
    "index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-09T07:03:50.078605Z",
     "start_time": "2017-09-09T07:03:50.071952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('X-ChromeLogger-Data',\n",
       " b'eyJ2ZXJzaW9uIjogIjAuNC4zIiwgImNvbHVtbnMiOiBbImxvZyIsICJiYWNrdHJhY2UiLCAidHlwZSJdLCAicm93cyI6IFtbWyJIZWxsbyBjb25zb2xlISJdLCAiPGlweXRob24taW5wdXQtMTAxLTgzNzA0ZTZjYWI5OT4gOiAxIiwgWyJsb2ciXV1dfQ==')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "console.log('Hello console!')\n",
    "console.get_header()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "49px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
